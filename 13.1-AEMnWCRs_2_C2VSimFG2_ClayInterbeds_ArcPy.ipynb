{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ed119a9",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The Product License has not been initialized.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_20640\\4036680660.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcsv\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0marcpy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minterpolate\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mgriddata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0marcpy\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0menv\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files\\ArcGIS\\Pro\\Resources\\ArcPy\\arcpy\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     75\u001b[0m     \u001b[1;32mimport\u001b[0m \u001b[0m_initagsenv\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 77\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0marcpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgeoprocessing\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mgp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     78\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0marcpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgeoprocessing\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0menv\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0marcpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgeoprocessing\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_base\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mgptooldoc\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_gptooldoc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files\\ArcGIS\\Pro\\Resources\\ArcPy\\arcpy\\geoprocessing\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;31m#\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;31m#email: contracts@esri.com\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_base\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Program Files\\ArcGIS\\Pro\\Resources\\ArcPy\\arcpy\\geoprocessing\\_base.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;31m#\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;31m#email: contracts@esri.com\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0marcgisscripting\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;34m\"\"\"Geoprocessing wrapper for the arcgisscripting library. Attempts to organize/make usage easier.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\ESRI\\conda\\envs\\arcgispro-py3-clone\\Lib\\site-packages\\arcgisscripting\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 131\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_arcgisscripting\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    132\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_arcgisscripting\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_addTimeInterval\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_analyzeForSD\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_attachLocator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m     \u001b[0m_convertWebMapToMapDocument\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_createGISServerConnectionFile\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: The Product License has not been initialized."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import csv\n",
    "import arcpy\n",
    "from scipy.interpolate import griddata\n",
    "from arcpy import env"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77f21029-07d9-43a5-80e7-082c3f940742",
   "metadata": {},
   "source": [
    "# import well completion reports and AEM coarse fractions combined \n",
    "# we assume you have combined and orginized these data so far\n",
    "# you aslo need to import IWFM conceptual model layers here we are using C2VSimFG model version 1.5( 4 layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b321a0d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load the data\n",
    "filtered_df = pd.read_csv(\"C:/Users/betebari/Documents/C2VSim_Texture/OSWCR/8-updated_all.csv\")\n",
    "\n",
    "# Create the new column for CLAY FRACTION\n",
    "filtered_df['ClayInterbed'] = (100.0 - filtered_df['Coarse'] )\n",
    "# or can be Descritption Column containing Clay  or Cl, CH, etc\n",
    "\n",
    "# Calculate total records and number of unique values\n",
    "total_records = len(filtered_df)\n",
    "\n",
    "# Find number of unique values in the WCRNUMBER column\n",
    "unique_wcrnumber = filtered_df['WellName'].nunique()\n",
    "\n",
    "# Print the result\n",
    "# Print total records and unique values per column\n",
    "print(f\"Total records: {total_records}\")\n",
    "print(f\"Number of unique WCRNUMBER values: {unique_wcrnumber}\")\n",
    "\n",
    "filtered_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "472839e3-c6e8-47f9-a6b5-67b81f55978f",
   "metadata": {},
   "outputs": [],
   "source": [
    "C2VSimFG_df = pd.read_csv(\"C:/c2vsimfg1.5/C2VSimFG_node_layering_assigned.csv\")\n",
    "\n",
    "# Drop the individual columns if not needed anymore\n",
    "C2VSimFG_df.drop(columns=['TotalThickness','top of BOFW','DC1','DC2','DC3','DC4','GSE'], inplace=True)\n",
    "\n",
    "C2VSimFG_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f893b34a-f96e-4219-8db5-8e2688564952",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure the DataFrame contains X and Y columns\n",
    "if 'X' not in filtered_df.columns or 'Y' not in filtered_df.columns:\n",
    "    raise ValueError(\"The DataFrame must contain 'X' and 'Y' columns for spatial coordinates.\")\n",
    "\n",
    "# Export to CSV\n",
    "csv_file = \"Filtered_WCRs_AEM.csv\"\n",
    "filtered_df.to_csv(csv_file, index=False)\n",
    "print(f\"CSV file exported: {csv_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6734d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows where 'ClayInterbed' is NaN and also drop rows where 'ClayInterbed' >= 80\n",
    "filtered_df = filtered_df.dropna(subset=['ClayInterbed'])\n",
    "filtered_df = filtered_df[filtered_df['ClayInterbed'] > 80]\n",
    "filtered_df['ClaybedThickness'] = filtered_df[['INTERVALEND'] - filtered_df[['INTERVALSTART'] \n",
    "\n",
    "# Drop the individual columns if not needed anymore\n",
    "filtered_df.drop(columns=['Kxy', 'SY','Ss','Kv','Coarse'], inplace=True)\n",
    "\n",
    "# Calculate total records and number of unique values\n",
    "total_records = len(filtered_df)\n",
    "\n",
    "# Find number of unique values in the WCRNUMBER column\n",
    "unique_wcrnumber = filtered_df['WellName'].nunique()\n",
    "\n",
    "# Print total records and unique values per column\n",
    "print(f\"Total records: {total_records}\")\n",
    "print(f\"Number of unique WCRNUMBER values: {unique_wcrnumber}\")\n",
    "\n",
    "# Print the result\n",
    "filtered_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c9fc68a-efc9-4de7-8887-d553d1256dad",
   "metadata": {},
   "source": [
    "# Apply Interpoltion method on C2VSimFG Layer 1 through Layer 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d4c047e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the workspace\n",
    "env.workspace = \"C:/Users/betebari/Documents/InSAR-Subsidence\"\n",
    "env.overwriteOutput = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e12f7d26-641f-4ea0-86ee-7052f97c00ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdb_path = \"C:/Users/betebari/Documents/InSAR-Subsidence/Subsidence.gdb\"\n",
    "if not arcpy.Exists(gdb_path):\n",
    "    arcpy.management.CreateFileGDB(os.path.dirname(gdb_path), os.path.basename(gdb_path))\n",
    "    print(f\"Geodatabase created: {gdb_path}\")\n",
    "else:\n",
    "    print(f\"Geodatabase already exists: {gdb_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d205787-cfe7-43fc-8b3e-bf342a89c454",
   "metadata": {},
   "outputs": [],
   "source": [
    "# File paths\n",
    "csv_file = \"C:/Users/betebari/Documents/InSAR-Subsidence/Filtered_WCRs_AEM.csv\"\n",
    "gdb_path = \"C:/Users/betebari/Documents/InSAR-Subsidence/Subsidence.gdb\"\n",
    "output_fc = f\"{gdb_path}/Filtered_WCRs_AEM\"\n",
    "\n",
    "# Verify the CSV file exists\n",
    "if not os.path.exists(csv_file):\n",
    "    raise FileNotFoundError(f\"CSV file not found: {csv_file}\")\n",
    "else:\n",
    "    print(f\"CSV file found: {csv_file}\")\n",
    "\n",
    "# Create the geodatabase if it doesn't exist\n",
    "if not arcpy.Exists(gdb_path):\n",
    "    arcpy.management.CreateFileGDB(os.path.dirname(gdb_path), os.path.basename(gdb_path))\n",
    "    print(f\"Created geodatabase: {gdb_path}\")\n",
    "else:\n",
    "    print(f\"Geodatabase exists: {gdb_path}\")\n",
    "\n",
    "# Delete existing feature class if necessary\n",
    "if arcpy.Exists(output_fc):\n",
    "    arcpy.management.Delete(output_fc)\n",
    "    print(f\"Deleted existing feature class: {output_fc}\")\n",
    "\n",
    "# Define spatial reference\n",
    "spatial_ref = arcpy.SpatialReference(26910)  # UTM Zone 10N NAD83\n",
    "\n",
    "# Create the point feature class\n",
    "try:\n",
    "    arcpy.management.XYTableToPoint(\n",
    "        in_table=csv_file,\n",
    "        out_feature_class=output_fc,\n",
    "        x_field=\"X\",  # Replace with actual X-coordinate column name\n",
    "        y_field=\"Y\",  # Replace with actual Y-coordinate column name\n",
    "        coordinate_system=spatial_ref\n",
    "    )\n",
    "    print(f\"Feature class created: {output_fc}\")\n",
    "except arcpy.ExecuteError:\n",
    "    print(f\"ArcPy ExecuteError: {arcpy.GetMessages(2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba06d96-8090-4f78-8d8a-2de91565b2d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from arcpy.sa import Spline\n",
    "\n",
    "# Set environment\n",
    "arcpy.env.overwriteOutput = True\n",
    "spatial_ref = arcpy.SpatialReference(26910)\n",
    "\n",
    "# Check Spatial Analyst extension\n",
    "if arcpy.CheckExtension(\"Spatial\") == \"Available\":\n",
    "    arcpy.CheckOutExtension(\"Spatial\")\n",
    "    print(\"Spatial Analyst extension checked out\")\n",
    "else:\n",
    "    raise RuntimeError(\"Spatial Analyst extension is required but not available.\")\n",
    "\n",
    "try:\n",
    "    # Ensure layers exist\n",
    "    layers = ['L1','A2','L2', 'L3', 'L4']\n",
    "    coords_df = C2VSimFG_df.copy()\n",
    "\n",
    "    # Check X and Y columns\n",
    "    if 'X' not in coords_df.columns or 'Y' not in coords_df.columns:\n",
    "        raise ValueError(\"The DataFrame must contain 'X' and 'Y' columns for spatial coordinates.\")\n",
    "\n",
    "    # Calculate cumulative values for layers\n",
    "    coords_df['L1_cum'] = coords_df['L1']  # L1_cum = L1\n",
    "    coords_df['L2_cum'] = coords_df['L1'] + coords_df['L2'] + coords_df['A2']  # L2_cum = L1 + A2 +L2\n",
    "    coords_df['L3_cum'] = coords_df['L2_cum'] +  coords_df['L3']  # L3_cum = L1 + A2 + L2 + L3\n",
    "    coords_df['L4_cum'] = coords_df['L3_cum']  + coords_df['L4']  # L4_cum = L1 + A2 + L2 + L3 + L4\n",
    "\n",
    "    # Replace NaN or missing values with 0 if needed\n",
    "    coords_df[['L1_cum', 'L2_cum', 'L3_cum', 'L4_cum']] = coords_df[['L1_cum', 'L2_cum', 'L3_cum', 'L4_cum']].fillna(0)\n",
    "\n",
    "    # Export DataFrame to CSV\n",
    "    csv_path = \"Cumulative_Layers.csv\"\n",
    "    coords_df.to_csv(csv_path, index=False)\n",
    "    print(f\"CSV file with cumulative layers exported: {csv_path}\")\n",
    "\n",
    "    # Create point feature class\n",
    "    gdb_path = \"C:/Users/betebari/Documents/InSAR-Subsidence/Subsidence.gdb\"\n",
    "    point_fc = os.path.join(gdb_path, \"point_fc\")\n",
    "\n",
    "    # Create geodatabase if it doesn't exist\n",
    "    if not arcpy.Exists(gdb_path):\n",
    "        arcpy.management.CreateFileGDB(os.path.dirname(gdb_path), os.path.basename(gdb_path))\n",
    "        print(f\"Geodatabase created: {gdb_path}\")\n",
    "\n",
    "    # Create point feature class from the cumulative CSV\n",
    "    arcpy.management.XYTableToPoint(\n",
    "        in_table=csv_path,\n",
    "        out_feature_class=point_fc,\n",
    "        x_field=\"X\",\n",
    "        y_field=\"Y\",\n",
    "        coordinate_system=spatial_ref\n",
    "    )\n",
    "    print(f\"Feature class created: {point_fc}\")\n",
    "\n",
    "    # List fields in the feature class\n",
    "    fields = [field.name for field in arcpy.ListFields(point_fc)]\n",
    "    print(\"Fields in the feature class:\", fields)\n",
    "\n",
    "    # Perform spline interpolation for each cumulative layer\n",
    "    cumulative_layers = ['L1_cum', 'L2_cum', 'L3_cum', 'L4_cum']\n",
    "    output_dir = \"C:/Users/betebari/Documents/InSAR-Subsidence\"\n",
    "    cell_size = 500  # Grid resolution\n",
    "\n",
    "    for layer in cumulative_layers:\n",
    "        output_raster = os.path.join(output_dir, f\"{layer}_interpolated.tif\")\n",
    "        try:\n",
    "            print(f\"Running Spline interpolation for {layer}...\")\n",
    "            spline_result = Spline(point_fc, layer, cell_size)\n",
    "            spline_result.save(output_raster)\n",
    "            print(f\"Spline interpolation complete for {layer}. Raster saved at {output_raster}\")\n",
    "        except arcpy.ExecuteError as e:\n",
    "            print(f\"ArcPy ExecuteError for {layer}: {e}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Unexpected error for {layer}: {e}\")\n",
    "\n",
    "except arcpy.ExecuteError as e:\n",
    "    print(f\"ArcPy ExecuteError: {e}\")\n",
    "except Exception as e:\n",
    "    print(f\"Unexpected error: {e}\")\n",
    "finally:\n",
    "    arcpy.CheckInExtension(\"Spatial\")\n",
    "    print(\"Spatial Analyst extension checked in\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "070daa59",
   "metadata": {},
   "source": [
    "# ExtractValuesToPoints operation(Interpolated C2VSimFG-L1 Thickness) to  points ((Filtered_WCRs_n_AEM ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1495eb99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Sanitize field names\n",
    "filtered_df.columns = [col.replace(' ', '_').replace('-', '_')[:64] for col in filtered_df.columns]\n",
    "\n",
    "# Step 2: Handle object fields\n",
    "for col in filtered_df.select_dtypes(include=['object']).columns:\n",
    "    filtered_df[col] = filtered_df[col].astype(str).str[:255]  # Convert to string and limit to 255 characters\n",
    "\n",
    "# Step 3: Replace null values\n",
    "filtered_df = filtered_df.fillna(0)  # Replace NaN with 0 for all columns\n",
    "\n",
    "# Step 4: Convert to NumPy array\n",
    "array = np.array(np.rec.fromrecords(filtered_df.values, names=filtered_df.columns.tolist()))\n",
    "\n",
    "# Step 5: Define output geodatabase and feature class\n",
    "gdb_path = \"C:/Users/betebari/Documents/InSAR-Subsidence\"\n",
    "if not arcpy.Exists(gdb_path):\n",
    "    arcpy.management.CreateFileGDB(os.path.dirname(gdb_path), os.path.basename(gdb_path))\n",
    "    print(f\"Created geodatabase: {gdb_path}\")\n",
    "\n",
    "output_fc = f\"{gdb_path}/Filtered_WCRs_AEM\"\n",
    "\n",
    "# Step 6: Define spatial reference\n",
    "spatial_ref = arcpy.SpatialReference(26910)  # UTM Zone 10N\n",
    "\n",
    "# Step 7: Check if feature class exists, and delete it\n",
    "if arcpy.Exists(output_fc):\n",
    "    arcpy.management.Delete(output_fc)\n",
    "    print(f\"Deleted existing feature class: {output_fc}\")\n",
    "\n",
    "# Step 8: Ensure 'X' and 'Y' fields exist\n",
    "if 'X' not in filtered_df.columns or 'Y' not in filtered_df.columns:\n",
    "    raise ValueError(\"Columns 'X' and 'Y' are required but not found in the DataFrame.\")\n",
    "\n",
    "# Step 9: Convert NumPy array to feature class\n",
    "arcpy.da.NumPyArrayToFeatureClass(array, output_fc, ['X', 'Y'], spatial_ref)\n",
    "\n",
    "print(f\"Feature class saved as: {output_fc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a4317e1-a761-4369-b935-bde16bd7aed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path where the geodatabase will be created\n",
    "workspace = \"C:/Users/betebari/Documents/InSAR-Subsidence\"\n",
    "gdb_name = \"Subsidence.gdb\"\n",
    "\n",
    "# Full path to the geodatabase\n",
    "gdb_path = os.path.join(workspace, gdb_name)\n",
    "\n",
    "# Check if the geodatabase already exists\n",
    "if not arcpy.Exists(gdb_path):\n",
    "    # Create the geodatabase\n",
    "    arcpy.management.CreateFileGDB(workspace, gdb_name)\n",
    "    print(f\"Geodatabase created: {gdb_path}\")\n",
    "else:\n",
    "    print(f\"Geodatabase already exists: {gdb_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f17622-614f-4c0a-94eb-f7ca28de6416",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the CSV file (replace this with your actual file)\n",
    "csv_file = \"Filtered_WCRs_AEM.csv\"\n",
    "\n",
    "# Path to the geodatabase\n",
    "gdb_path = \"C:/Users/betebari/Documents/InSAR-Subsidence/Subsidence.gdb\"\n",
    "\n",
    "# Output feature class name\n",
    "output_fc = f\"{gdb_path}/Filtered_WCRs_AEM\"\n",
    "\n",
    "# Define spatial reference (UTM Zone 10N)\n",
    "spatial_ref = arcpy.SpatialReference(26910)\n",
    "\n",
    "# Create the point feature class from CSV\n",
    "arcpy.management.XYTableToPoint(\n",
    "    in_table=csv_file,\n",
    "    out_feature_class=output_fc,\n",
    "    x_field=\"X\",  # Replace with the name of the X-coordinate field in your CSV\n",
    "    y_field=\"Y\",  # Replace with the name of the Y-coordinate field in your CSV\n",
    "    coordinate_system=spatial_ref\n",
    ")\n",
    "\n",
    "print(f\"Feature class created: {output_fc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a31ea85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check out the Spatial Analyst extension\n",
    "if arcpy.CheckExtension(\"Spatial\") == \"Available\":\n",
    "    arcpy.CheckOutExtension(\"Spatial\")\n",
    "    print(\"Spatial Analyst extension checked out\")\n",
    "else:\n",
    "    raise RuntimeError(\"Spatial Analyst extension is not available or licensed.\")\n",
    "\n",
    "try:\n",
    "    # Workspace and file paths\n",
    "    arcpy.env.workspace = \"C:/Users/betebari/Documents/InSAR-Subsidence/Subsidence1.gdb\"\n",
    "    raster_folder = \"C:/Users/betebari/Documents/InSAR-Subsidence/\"\n",
    "    input_points = \"C:/Users/betebari/Documents/C2VSim_Texture/Aq-Params/C2VSimFG_points_4layers.gdb/Filtered_WCRs_AEM\"\n",
    "\n",
    "    # Validate input points feature class\n",
    "    if not arcpy.Exists(input_points):\n",
    "        raise FileNotFoundError(f\"Input points feature class '{input_points}' does not exist.\")\n",
    "\n",
    "    # Check and remove the RASTERVALU field if it exists\n",
    "    fields = [f.name for f in arcpy.ListFields(input_points)]\n",
    "    if \"RASTERVALU\" in fields:\n",
    "        print(\"Field 'RASTERVALU' exists. Deleting it to avoid conflicts...\")\n",
    "        arcpy.management.DeleteField(input_points, \"RASTERVALU\")\n",
    "        print(\"Field 'RASTERVALU' deleted.\")\n",
    "\n",
    "    # List of rasters to process\n",
    "    rasters = ['L1_cum_interpolated.tif', 'L2_cum_interpolated.tif', 'L3_cum_interpolated.tif', 'L4_cum_interpolated.tif']\n",
    "\n",
    "    # Iterate over raster files\n",
    "    for raster in rasters:\n",
    "        print(f\"Processing {raster}...\")\n",
    "\n",
    "        # Define raster and output feature class\n",
    "        raster_path = os.path.join(raster_folder, raster)\n",
    "        if not arcpy.Exists(raster_path):\n",
    "            print(f\"Raster '{raster_path}' does not exist. Skipping...\")\n",
    "            continue\n",
    "\n",
    "        output_fc = os.path.join(arcpy.env.workspace, f\"Extracted_{os.path.splitext(raster)[0]}\")\n",
    "\n",
    "        # Perform ExtractValuesToPoints\n",
    "        arcpy.sa.ExtractValuesToPoints(\n",
    "            in_point_features=input_points,\n",
    "            in_raster=raster_path,\n",
    "            out_point_features=output_fc,\n",
    "            interpolate_values=\"NONE\",\n",
    "            add_attributes=\"VALUE_ONLY\"\n",
    "        )\n",
    "        print(f\"Values extracted to {output_fc}\")\n",
    "\n",
    "        # Export to CSV\n",
    "        csv_output = os.path.join(raster_folder, f\"{os.path.splitext(raster)[0]}_output.csv\")\n",
    "        fields = [f.name for f in arcpy.ListFields(output_fc) if f.name.lower() != 'shape']\n",
    "        fields.append('SHAPE@XY')\n",
    "\n",
    "        with open(csv_output, 'w', newline='') as csvfile:\n",
    "            writer = csv.writer(csvfile)\n",
    "            writer.writerow(fields[:-1] + ['X', 'Y'])\n",
    "\n",
    "            with arcpy.da.SearchCursor(output_fc, fields) as cursor:\n",
    "                for row in cursor:\n",
    "                    row_list = list(row[:-1])\n",
    "                    x, y = row[-1]\n",
    "                    row_list.extend([x, y])\n",
    "                    writer.writerow(row_list)\n",
    "\n",
    "        print(f\"CSV exported to {csv_output}\")\n",
    "\n",
    "except arcpy.ExecuteError as e:\n",
    "    print(f\"ArcPy ExecuteError: {e}\")\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"FileNotFoundError: {e}\")\n",
    "except Exception as e:\n",
    "    print(f\"Unexpected error: {e}\")\n",
    "finally:\n",
    "    arcpy.CheckInExtension(\"Spatial\")\n",
    "    print(\"Spatial Analyst extension checked in\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b93009fb-c5eb-4b99-881d-47f245b0ac3f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:conda-arcgispro-py3-clone]",
   "language": "python",
   "name": "conda-env-conda-arcgispro-py3-clone-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
