{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7fb152cc-626c-40f0-aa5f-2454f2f73dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_pdf import PdfPages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "921487ab-de03-4514-b4b4-084a823fa343",
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes_file = r'C:\\c2vsimfg1.5\\Preprocessor\\C2VSimFG_Nodes.dat'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7a9d7cde-5a22-448d-8c41-a933ba54c2b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "stratigraphy_file = r'C:\\C2VSimFG1.5\\Preprocessor\\C2VSimFG_Stratigraphy.dat'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "981eb962-aa16-4b36-8684-de4484fab9ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "groundwater_param_file = r'C:\\C2VSimFG1.5\\Simulation\\Groundwater\\C2VSimFG_Groundwater1974.dat'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a43cfc53",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\betebari\\AppData\\Local\\Temp\\ipykernel_23216\\1300167886.py:1: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  nodes = pd.read_csv(nodes_file, header=None, \\\n"
     ]
    }
   ],
   "source": [
    "nodes = pd.read_csv(nodes_file, header=None, \\\n",
    "                    names=['NodeID', 'X', 'Y'], skiprows=90, delim_whitespace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "474052e0",
   "metadata": {},
   "source": [
    "# nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1fb5e221",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\betebari\\AppData\\Local\\Temp\\ipykernel_23216\\2355816574.py:1: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  stratigraphy = pd.read_csv(stratigraphy_file, header=None, names=['NodeID', 'GSE', 'A1', 'L1', 'A2',\\\n"
     ]
    }
   ],
   "source": [
    "stratigraphy = pd.read_csv(stratigraphy_file, header=None, names=['NodeID', 'GSE', 'A1', 'L1', 'A2',\\\n",
    "                                'L2', 'A3', 'L3', 'A4', 'L4'], skiprows=107, delim_whitespace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "733756c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "stratigraphy.describe().to_csv(r'C:\\C2VSimFG1.5\\QA_QC\\stratigraphy.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1782cefd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NodeID             object\n",
      "X                 float64\n",
      "Y                 float64\n",
      "GSE               float64\n",
      "A1                float64\n",
      "L1                float64\n",
      "A2                float64\n",
      "L2                float64\n",
      "A3                float64\n",
      "L3                float64\n",
      "A4                float64\n",
      "L4                float64\n",
      "TotalThickness    float64\n",
      "dtype: object\n",
      "  NodeID            X            Y     GSE   A1      L1   A2      L2   A3  \\\n",
      "0      1  554210.8184  4498111.367  616.86  0.0  136.39  0.0  122.35  0.0   \n",
      "1      2  556163.7904  4499563.238  682.02  0.0  200.44  0.0  127.51  0.0   \n",
      "2      3  557356.8226  4501930.315  701.69  0.0  203.87  0.0  137.82  0.0   \n",
      "3      4  559132.7039  4503200.652  682.44  0.0  171.15  0.0  145.29  0.0   \n",
      "4      5  561893.4429  4503238.309  803.87  0.0  287.87  0.0  148.00  0.0   \n",
      "\n",
      "       L3   A4    L4  TotalThickness  \n",
      "0  124.57  0.0  50.0          433.31  \n",
      "1  104.08  0.0  50.0          482.03  \n",
      "2   82.27  0.0  50.0          473.96  \n",
      "3   75.99  0.0  50.0          442.43  \n",
      "4   80.04  0.0  50.0          565.91  \n"
     ]
    }
   ],
   "source": [
    "# Ensure 'NodeID' has the same data type in both DataFrames\n",
    "nodes['NodeID'] = nodes['NodeID'].astype(str)  # Convert to string\n",
    "stratigraphy['NodeID'] = stratigraphy['NodeID'].astype(str)  # Convert to string\n",
    "\n",
    "# Merge the DataFrames\n",
    "node_stratigraphy = pd.merge(nodes, stratigraphy, on='NodeID')\n",
    "\n",
    "# Convert object columns to numeric\n",
    "numeric_columns = ['A1', 'L1', 'A2', 'L2', 'A3', 'L3', 'A4', 'L4']\n",
    "for col in numeric_columns:\n",
    "    node_stratigraphy[col] = pd.to_numeric(node_stratigraphy[col], errors='coerce')\n",
    "\n",
    "# Fill NaN values with 0\n",
    "node_stratigraphy = node_stratigraphy.fillna(0)\n",
    "\n",
    "# Recalculate TotalThickness\n",
    "node_stratigraphy['TotalThickness'] = (\n",
    "    node_stratigraphy['A1'] + node_stratigraphy['L1'] +\n",
    "    node_stratigraphy['A2'] + node_stratigraphy['L2'] +\n",
    "    node_stratigraphy['A3'] + node_stratigraphy['L3'] +\n",
    "    node_stratigraphy['A4'] + node_stratigraphy['L4']\n",
    ")\n",
    "\n",
    "# Verify the data types\n",
    "print(node_stratigraphy.dtypes)\n",
    "\n",
    "# Display the first few rows\n",
    "print(node_stratigraphy.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "022a15a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving PNG file...\n",
      "File saved successfully.\n"
     ]
    }
   ],
   "source": [
    "# Define the column to plot\n",
    "field = 'TotalThickness'  # Replace with the correct column name\n",
    "title = 'Total Thickness of C2VSimFG'\n",
    "file_name = 'ModelThickness.png'\n",
    "\n",
    "# Ensure the output directory exists\n",
    "output_dir = 'C:/Users/betebari/Documents/InSAR-Subsidence'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Find max and min values\n",
    "max_value = node_stratigraphy[field].max()\n",
    "min_value = node_stratigraphy[field].min()\n",
    "\n",
    "# Extract max X and Y coordinates\n",
    "max_x = node_stratigraphy[node_stratigraphy[field] == max_value]['X'].iloc[0]\n",
    "max_y = node_stratigraphy[node_stratigraphy[field] == max_value]['Y'].iloc[0]\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(11, 17))\n",
    "plt.scatter(node_stratigraphy['X'], node_stratigraphy['Y'], s=4, c=node_stratigraphy[field], cmap='viridis')\n",
    "plt.grid(True)\n",
    "plt.xlabel('Easting (m)')\n",
    "plt.ylabel('Northing (m)')\n",
    "plt.title(title)\n",
    "\n",
    "# Annotate the maximum value\n",
    "plt.annotate('{:6.2f} ft'.format(max_value), \n",
    "             xy=(max_x, max_y),\n",
    "             xytext=(max_x + 8000, max_y - 50000), \n",
    "             arrowprops=dict(arrowstyle=\"->\", connectionstyle=\"arc3,rad=0.3\"))\n",
    "\n",
    "# Colorbar\n",
    "cbar = plt.colorbar()\n",
    "cbar.set_label('Thickness in Feet', fontsize=20)\n",
    "\n",
    "# Save the file\n",
    "print(\"Saving PNG file...\")\n",
    "plt.savefig(os.path.join(output_dir, file_name))\n",
    "plt.close()\n",
    "print(\"File saved successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfa39cb3-9561-4281-895f-c0c2e054f992",
   "metadata": {},
   "source": [
    "# Visualize C2VSimFG - layering 1 & 2 & 3 & 4 & Aquitards' data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "20438a25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing layer: L1\n",
      "Added normalized column for L1.\n",
      "\n",
      "Processing layer: A2\n",
      "Added normalized column for A2.\n",
      "\n",
      "Processing layer: L2\n",
      "Added normalized column for L2.\n",
      "\n",
      "Processing layer: L3\n",
      "Added normalized column for L3.\n",
      "\n",
      "Processing layer: L4\n",
      "Added normalized column for L4.\n",
      "\n",
      "Data saved to 'Processed_Node_Stratigraphy.csv'.\n",
      "Results saved to 'Layer_Analysis_Results.pdf'.\n"
     ]
    }
   ],
   "source": [
    "# List of layer columns\n",
    "layers = ['L1', 'A2', 'L2', 'L3', 'L4']\n",
    "\n",
    "# Create a PDF file to save plots and results\n",
    "output_pdf = 'Layer_Analysis_Results.pdf'\n",
    "with PdfPages(output_pdf) as pdf:\n",
    "    for layer in layers:\n",
    "        # Print the layer name\n",
    "        print(f\"Processing layer: {layer}\")\n",
    "        \n",
    "        # Scatter plot for the layer\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        plt.scatter(node_stratigraphy['X'], node_stratigraphy['Y'], s=4, c=node_stratigraphy[layer], cmap='viridis')\n",
    "        plt.colorbar(label=f'{layer} Thickness')\n",
    "        plt.title(f'Spatial Distribution of {layer}')\n",
    "        plt.xlabel('Easting (m)')\n",
    "        plt.ylabel('Northing (m)')\n",
    "        plt.grid(True)\n",
    "        \n",
    "        # Save the plot to the PDF\n",
    "        pdf.savefig()\n",
    "        plt.close()\n",
    "\n",
    "        # Calculate statistics for the layer\n",
    "        max_value = node_stratigraphy[layer].max()\n",
    "        min_value = node_stratigraphy[layer].min()\n",
    "        mean_value = node_stratigraphy[layer].mean()\n",
    "        \n",
    "        # Create a new figure for statistics\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        plt.axis('off')  # Turn off axes\n",
    "        stats_text = (\n",
    "            f\"Layer: {layer}\\n\\n\"\n",
    "            f\"Maximum Value: {max_value:.2f}\\n\"\n",
    "            f\"Minimum Value: {min_value:.2f}\\n\"\n",
    "            f\"Mean Value: {mean_value:.2f}\\n\"\n",
    "        )\n",
    "        plt.text(0.1, 0.5, stats_text, fontsize=12, va='center')\n",
    "        \n",
    "        # Save the statistics to the PDF\n",
    "        pdf.savefig()\n",
    "        plt.close()\n",
    "\n",
    "        # Add a normalized column for the layer\n",
    "        node_stratigraphy[f'{layer}_Normalized'] = (node_stratigraphy[layer] - min_value) / (max_value - min_value)\n",
    "        print(f\"Added normalized column for {layer}.\\n\")\n",
    "    \n",
    "    # Add a summary page to the PDF\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.axis('off')\n",
    "    plt.text(0.1, 0.5, \"Layer Analysis Completed\\n\\nResults saved successfully.\", fontsize=16, va='center')\n",
    "    pdf.savefig()\n",
    "    plt.close()\n",
    "\n",
    "# Save the updated DataFrame to CSV\n",
    "node_stratigraphy.to_csv('Processed_Node_Stratigraphy.csv', index=False)\n",
    "print(\"Data saved to 'Processed_Node_Stratigraphy.csv'.\")\n",
    "print(f\"Results saved to '{output_pdf}'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70af76b4-761a-46f1-9f1f-8f9b0b44b7bc",
   "metadata": {},
   "source": [
    "# Step (1) Convert C2VSimFG_Groundwater1974.dat (Aquifer Parameter) to csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "a51e6b5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to C://Users//betebari//Documents//InSAR-Subsidence//Parsed_AquiferParams.csv\n",
      "  NodeID  Layer            X            Y          PKH         PS          PN  \\\n",
      "0      1      1  554210.8184  4498111.367  61.00634182  0.110E-04  0.10819630   \n",
      "1      1      2  554210.8184  4498111.367  41.02325849  0.741E-05  0.13809980   \n",
      "2      1      3  554210.8184  4498111.367  22.16909207  0.117E-04  0.10220482   \n",
      "3      1      4  554210.8184  4498111.367  24.85191058  0.801E-05  0.13311384   \n",
      "4      2      1  556163.7904  4499563.238  48.58233323  0.151E-04  0.09856682   \n",
      "\n",
      "           PV          PL  \n",
      "0  0.00000000  3.35477695  \n",
      "1  0.00000000  2.10683276  \n",
      "2  0.00000000  1.10271885  \n",
      "3  0.00000000  1.12947233  \n",
      "4  0.00000000  2.19999392  \n"
     ]
    }
   ],
   "source": [
    "# Input and output file paths\n",
    "parsed_data_path = r'C://c2vsimfg1.5//Simulation//Groundwater//C2VSimFG_Groundwater1974.dat'\n",
    "output_file_path = r'C://Users//betebari//Documents//InSAR-Subsidence//Parsed_AquiferParams.csv'\n",
    "\n",
    "#   ID   ;   Groundwater node number  NodeID\n",
    "#   PKH  ;   Hydraulic conductivity; [L/T]\n",
    "#   PS   ;   Specific storage; [1/L]\n",
    "#   PN   ;   Specific yield; [L/L]\n",
    "#   PV   ;   Aquitard vertical hydraulic conductivity; [L/T]\n",
    "#   PL   ;   Aquifer vertical hydraulic conductivity; [L/T]\n",
    "\n",
    "# Define columns for the output\n",
    "columns = ['NodeID', 'Layer', 'X', 'Y', 'PKH', 'PS', 'PN', 'PV', 'PL']\n",
    "output_data = []\n",
    "\n",
    "# Define line range for processing\n",
    "start_line = 54959\n",
    "end_line = 175675\n",
    "\n",
    "# Lookup dictionary for X and Y coordinates based on NodeID\n",
    "xy_lookup = node_stratigraphy.set_index('NodeID')[['X', 'Y']].to_dict('index')\n",
    "\n",
    "# Read and process the input file\n",
    "with open(parsed_data_path, 'r', newline='') as input_file:\n",
    "    current_node_id = None\n",
    "    current_layer = 0\n",
    "    current_pkh = current_ps = current_pn = current_pv = current_pl = None\n",
    "\n",
    "    for i, line in enumerate(input_file):\n",
    "        # Skip lines outside the specified range\n",
    "        if i < start_line or i > end_line:\n",
    "            continue\n",
    "\n",
    "        # Skip comment lines or empty lines\n",
    "        if line[0] in ['C', '*'] or line.strip() == '':\n",
    "            continue\n",
    "\n",
    "        # Split the line into components\n",
    "        line_list = line.split()\n",
    "\n",
    "        # Node rows (start with numeric ID and at least 6 fields)\n",
    "        if len(line_list) >= 6 and line_list[0].isdigit():\n",
    "            current_node_id = line_list[0]\n",
    "            current_layer = 1\n",
    "            current_pkh, current_ps, current_pn, current_pv, current_pl = line_list[1:6]\n",
    "            xy = xy_lookup.get(current_node_id, {'X': None, 'Y': None})\n",
    "            x, y = xy['X'], xy['Y']\n",
    "            output_data.append([current_node_id, current_layer, x, y, current_pkh, current_ps, current_pn, current_pv, current_pl])\n",
    "\n",
    "        # Continuation rows (exactly 5 fields)\n",
    "        elif len(line_list) == 5:\n",
    "            if current_node_id is not None:\n",
    "                current_layer += 1\n",
    "                current_pkh, current_ps, current_pn, current_pv, current_pl = line_list\n",
    "                xy = xy_lookup.get(current_node_id, {'X': None, 'Y': None})\n",
    "                x, y = xy['X'], xy['Y']\n",
    "                output_data.append([current_node_id, current_layer, x, y, current_pkh, current_ps, current_pn, current_pv, current_pl])\n",
    "            else:\n",
    "                print(f\"Skipping malformed line at index {i}: {line.strip()}\")\n",
    "        else:\n",
    "            print(f\"Skipping unrecognized line at index {i}: {line.strip()}\")\n",
    "\n",
    "# Convert processed data to a DataFrame\n",
    "groundwater_param = pd.DataFrame(output_data, columns=columns)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "groundwater_param.to_csv(output_file_path, index=False)\n",
    "print(f\"Data saved to {output_file_path}\")\n",
    "\n",
    "# Print the first few rows to verify\n",
    "print(groundwater_param.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa3b8400-69f7-4a3e-8123-40177f34a24d",
   "metadata": {},
   "source": [
    "# Step (2) Convert Aquifer Params(Hydraulic conductivity;Specific yield; etc ...) to Pivotted by Layer  Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "b75f17f3-9eb0-47a9-856b-d7b1ade270ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pivoted data saved to C://Users//betebari//Documents//InSAR-Subsidence//Pivoted_AquiferParams.csv\n",
      "   NodeID            X            Y     PKH_L1     PKH_L2     PKH_L3  \\\n",
      "0       1  554210.8184  4498111.367  61.006342  41.023258  22.169092   \n",
      "1       2  556163.7904  4499563.238  48.582333  28.634508  15.974680   \n",
      "2       3  557356.8226  4501930.315  44.354940  26.761389  15.331797   \n",
      "3       4  559132.7039  4503200.652  42.221503  28.970161  15.601213   \n",
      "4       5  561893.4429  4503238.309  32.068517  21.078297  12.326883   \n",
      "\n",
      "      PKH_L4     PS_L1     PS_L2     PS_L3  ...     PN_L3     PN_L4  PV_L1  \\\n",
      "0  24.851911  0.000011  0.000007  0.000012  ...  0.102205  0.133114    0.0   \n",
      "1  23.806886  0.000015  0.000013  0.000017  ...  0.086342  0.132544    0.0   \n",
      "2  22.826615  0.000021  0.000017  0.000022  ...  0.086610  0.125448    0.0   \n",
      "3  22.419005  0.000026  0.000020  0.000025  ...  0.085654  0.119488    0.0   \n",
      "4  18.159367  0.000028  0.000022  0.000028  ...  0.085480  0.111950    0.0   \n",
      "\n",
      "   PV_L2  PV_L3  PV_L4     PL_L1     PL_L2     PL_L3     PL_L4  \n",
      "0    0.0    0.0    0.0  3.354777  2.106833  1.102719  1.129472  \n",
      "1    0.0    0.0    0.0  2.199994  1.151712  0.686924  0.835567  \n",
      "2    0.0    0.0    0.0  1.630384  0.835708  0.521772  0.613106  \n",
      "3    0.0    0.0    0.0  1.435670  0.781894  0.466774  0.520788  \n",
      "4    0.0    0.0    0.0  0.935521  0.467401  0.314952  0.361054  \n",
      "\n",
      "[5 rows x 23 columns]\n"
     ]
    }
   ],
   "source": [
    "# Input and output file paths\n",
    "parsed_data_path = r'C://Users//betebari//Documents//InSAR-Subsidence//Parsed_AquiferParams.csv'\n",
    "output_pivot_path = r'C://Users//betebari//Documents//InSAR-Subsidence//Pivoted_AquiferParams.csv'\n",
    "\n",
    "# Load the parsed data into a DataFrame\n",
    "groundwater_param = pd.read_csv(parsed_data_path)\n",
    "\n",
    "# Pivot the data to create columns for each layer\n",
    "pivoted_data = groundwater_param.pivot(index=['NodeID', 'X', 'Y'], columns='Layer', values=['PKH', 'PS', 'PN', 'PV', 'PL'])\n",
    "\n",
    "# Flatten the multi-level column index\n",
    "pivoted_data.columns = [f'{col[0]}_L{col[1]}' for col in pivoted_data.columns]\n",
    "\n",
    "# Reset the index to make 'ID', 'X', and 'Y' columns\n",
    "pivoted_data.reset_index(inplace=True)\n",
    "\n",
    "# Save the pivoted data to a CSV file\n",
    "pivoted_data.to_csv(output_pivot_path, index=False)\n",
    "print(f\"Pivoted data saved to {output_pivot_path}\")\n",
    "\n",
    "# Print the first few rows to verify\n",
    "print(pivoted_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "759f2fac-515b-48df-a61f-4c07dc786686",
   "metadata": {},
   "source": [
    "# Step (3) Convert Subsidence Parameters to csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "58ef58d0-7b59-4f63-8761-13c24c7e2b64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping unrecognized line at line 907: C-------------------------------------------------------------------------------\n",
      "Data saved to C://Users//betebari//Documents//InSAR-Subsidence//Parsed_Subsidence.csv\n",
      "  NodeID  Layer            X            Y           SCE       SCI      DC  \\\n",
      "0      1      1  554210.8184  4498111.367  1.668800e-07  0.000016   93.97   \n",
      "1      1      2  554210.8184  4498111.367  1.668800e-07  0.000016   49.00   \n",
      "2      1      3  554210.8184  4498111.367  1.668800e-07  0.000016   49.00   \n",
      "3      1      4  554210.8184  4498111.367  1.668800e-07  0.000016   24.17   \n",
      "4      2      1  556163.7904  4499563.238  1.635400e-07  0.000020  149.00   \n",
      "\n",
      "   DCMIN       HC  \n",
      "0    1.0  99999.0  \n",
      "1    1.0  99999.0  \n",
      "2    1.0  99999.0  \n",
      "3    1.0  99999.0  \n",
      "4    1.0  99999.0  \n"
     ]
    }
   ],
   "source": [
    "# Input and output file paths\n",
    "input_file_path = r'C://c2vsimfg1.5//Simulation//Groundwater//C2VSimFG_Subsidence.dat'\n",
    "output_file_path = r'C://Users//betebari//Documents//InSAR-Subsidence//Parsed_Subsidence.csv'\n",
    "\n",
    "#\tID\t;\tGroundwater\tnode number ;or\tNodeID\t\t\t\t\t\t\t\t\t\t\t\n",
    "#\tSCE\t;\tElastic\tstorage\tcoefficient;\t[1/L]\t\t\t\t\t\t\t\t\t\t\t\n",
    "#\tSCI\t;\tInelastic\tstorage\tcoefficient;\t[1/L]\t\t\t\t\t\t\t\t\t\t\t\n",
    "#\tDC\t;\tInterbed\tthickness;\t[L]\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "#\tDCMIN;\tMinimum\tinterbed\tthickness;\t[L]\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "#\tHC\t;\tPre-compaction\thydraulic\thead\t(use\t99999\tto\tuse\tinitial\theads);\t[L]\t\t\t\t\t\n",
    "#\t*Note*\tThe\tabove\tland\tsubsidence\tparameters\tare\tonly\tfor\tinterbed\tlayers\t(i.e.\tclay\tlayers)\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "\n",
    "# Initialize variables\n",
    "columns = [\"NodeID\", \"Layer\", \"X\", \"Y\", \"SCE\", \"SCI\", \"DC\", \"DCMIN\", \"HC\"]\n",
    "output_data = []\n",
    "current_node_id = None\n",
    "current_layer = 0\n",
    "\n",
    "# Define line range\n",
    "start_line = 907\n",
    "end_line = 121623\n",
    "\n",
    "# Initialize variables\n",
    "columns = [\"NodeID\", \"Layer\", \"X\", \"Y\", \"SCE\", \"SCI\", \"DC\", \"DCMIN\", \"HC\"]\n",
    "output_data = []\n",
    "current_node_id = None\n",
    "current_layer = 0\n",
    "\n",
    "# Define line range for processing\n",
    "start_line = 907\n",
    "end_line = 121623\n",
    "\n",
    "# Process the input file\n",
    "with open(input_file_path, \"r\") as file:\n",
    "    for i, line in enumerate(file, start=1):  # Line numbers start at 1\n",
    "        # Skip lines outside the range\n",
    "        if i < start_line or i > end_line:\n",
    "            continue\n",
    "\n",
    "        line = line.rstrip()\n",
    "\n",
    "        # Skip empty lines\n",
    "        if not line:\n",
    "            continue\n",
    "\n",
    "        # Node row: starts with NodeID\n",
    "        if line[0].isdigit():\n",
    "            parts = line.split()\n",
    "            if len(parts) < 6:  # Check if there are enough fields\n",
    "                print(f\"Skipping malformed node row at line {i}: {line}\")\n",
    "                continue\n",
    "\n",
    "            current_node_id = parts[0]\n",
    "            current_layer = 1  # Reset layer counter\n",
    "            sce, sci, dc, dcmin, hc = parts[1:6]\n",
    "\n",
    "            # Get X and Y coordinates\n",
    "            xy = xy_lookup.get(current_node_id, {\"X\": None, \"Y\": None})\n",
    "            output_data.append([\n",
    "                current_node_id,\n",
    "                current_layer,\n",
    "                xy[\"X\"],\n",
    "                xy[\"Y\"],\n",
    "                float(sce),\n",
    "                float(sci),\n",
    "                float(dc),\n",
    "                float(dcmin),\n",
    "                float(hc),\n",
    "            ])\n",
    "\n",
    "        # Continuation row: starts with whitespace\n",
    "        elif line[0].isspace():\n",
    "            parts = line.split()\n",
    "            if len(parts) < 5:  # Check if there are enough fields\n",
    "                print(f\"Skipping malformed continuation row at line {i}: {line}\")\n",
    "                continue\n",
    "\n",
    "            current_layer += 1  # Increment layer\n",
    "            sce, sci, dc, dcmin, hc = parts[:5]\n",
    "\n",
    "            # Get X and Y coordinates\n",
    "            xy = xy_lookup.get(current_node_id, {\"X\": None, \"Y\": None})\n",
    "            output_data.append([\n",
    "                current_node_id,\n",
    "                current_layer,\n",
    "                xy[\"X\"],\n",
    "                xy[\"Y\"],\n",
    "                float(sce),\n",
    "                float(sci),\n",
    "                float(dc),\n",
    "                float(dcmin),\n",
    "                float(hc),\n",
    "            ])\n",
    "        else:\n",
    "            print(f\"Skipping unrecognized line at line {i}: {line}\")\n",
    "\n",
    "# Convert to DataFrame\n",
    "df = pd.DataFrame(output_data, columns=columns)\n",
    "\n",
    "# Save to CSV\n",
    "df.to_csv(output_file_path, index=False)\n",
    "print(f\"Data saved to {output_file_path}\")\n",
    "\n",
    "# Display the first few rows for verification\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "979c88e2-fc8b-4919-a118-df0b0fe2726b",
   "metadata": {},
   "source": [
    "# Step (4) Pivot subsidence data by Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "59643ba7-d254-4272-8230-65a1b77b5866",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique layers in the input data: [1 2 3 4]\n",
      "Pivoted data saved to C://Users//betebari//Documents//InSAR-Subsidence//pivoted_Subsidence.csv\n",
      "   NodeID            X            Y        SCE_L1        SCE_L2        SCE_L3  \\\n",
      "0       1  554210.8184  4498111.367  1.668800e-07  1.668800e-07  1.668800e-07   \n",
      "1       2  556163.7904  4499563.238  1.635400e-07  1.635400e-07  1.635400e-07   \n",
      "2       3  557356.8226  4501930.315  1.588900e-07  1.588900e-07  1.588900e-07   \n",
      "3       4  559132.7039  4503200.652  1.556400e-07  1.556400e-07  1.556400e-07   \n",
      "4       5  561893.4429  4503238.309  1.530400e-07  1.530400e-07  1.530400e-07   \n",
      "\n",
      "         SCE_L4    SCI_L1    SCI_L2    SCI_L3  ...  DC_L3  DC_L4  DCMIN_L1  \\\n",
      "0  1.668800e-07  0.000016  0.000016  0.000016  ...   49.0  24.17       1.0   \n",
      "1  1.635400e-07  0.000020  0.000020  0.000020  ...   49.0  24.18       1.0   \n",
      "2  1.588900e-07  0.000025  0.000025  0.000025  ...   49.0  26.65       1.0   \n",
      "3  1.556400e-07  0.000029  0.000029  0.000029  ...   49.0  28.78       1.0   \n",
      "4  1.530400e-07  0.000032  0.000032  0.000032  ...   49.0  31.57       1.0   \n",
      "\n",
      "   DCMIN_L2  DCMIN_L3  DCMIN_L4    HC_L1    HC_L2    HC_L3    HC_L4  \n",
      "0       1.0       1.0       1.0  99999.0  99999.0  99999.0  99999.0  \n",
      "1       1.0       1.0       1.0  99999.0  99999.0  99999.0  99999.0  \n",
      "2       1.0       1.0       1.0  99999.0  99999.0  99999.0  99999.0  \n",
      "3       1.0       1.0       1.0  99999.0  99999.0  99999.0  99999.0  \n",
      "4       1.0       1.0       1.0  99999.0  99999.0  99999.0  99999.0  \n",
      "\n",
      "[5 rows x 23 columns]\n"
     ]
    }
   ],
   "source": [
    "# File paths\n",
    "parsed_data_path = r'C://Users//betebari//Documents//InSAR-Subsidence//Parsed_Subsidence.csv'\n",
    "output_pivot_path = r'C://Users//betebari//Documents//InSAR-Subsidence//pivoted_Subsidence.csv'\n",
    "\n",
    "# Load the parsed data into a DataFrame\n",
    "groundwater_param = pd.read_csv(parsed_data_path)\n",
    "\n",
    "# Verify the unique values in the 'Layer' column\n",
    "print(\"Unique layers in the input data:\", groundwater_param['Layer'].unique())\n",
    "\n",
    "# Pivot the data to create columns for each layer\n",
    "pivoted_data = groundwater_param.pivot(index=['NodeID', 'X', 'Y'], columns='Layer', values=['SCE', 'SCI', 'DC', 'DCMIN', 'HC'])\n",
    "\n",
    "# Flatten the multi-level column index\n",
    "pivoted_data.columns = [f'{col[0]}_L{col[1]}' for col in pivoted_data.columns]\n",
    "\n",
    "# Reset the index to make 'NodeID', 'X', and 'Y' columns\n",
    "pivoted_data.reset_index(inplace=True)\n",
    "\n",
    "# Save the pivoted data to a CSV file\n",
    "pivoted_data.to_csv(output_pivot_path, index=False)\n",
    "print(f\"Pivoted data saved to {output_pivot_path}\")\n",
    "\n",
    "# Print the first few rows to verify\n",
    "print(pivoted_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de68140d-893a-414c-aa9c-ee1c80fc9761",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
